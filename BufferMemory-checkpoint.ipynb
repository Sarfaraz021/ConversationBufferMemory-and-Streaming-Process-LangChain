{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "313e76ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e9ecb3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI (Artificial Intelligence) is a branch of computer science that focuses on creating intelligent machines that can think and act like humans. AI systems are designed to learn from their environment and experiences, and can be used to solve complex problems and automate tasks. AI is used in a variety of applications, including robotics, natural language processing, computer vision, and machine learning."
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "# llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n",
    "# resp = llm(\"What is AI.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9d4fd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ee439e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(streaming=True, callbacks=[StreamingStdOutCallbackHandler()], temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bc657dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6f49d071",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we have all the information. Elon Musk was born on June 28, 1971 in Pretoria, South Africa.\n",
      "\n",
      "AI (Artificial Intelligence) is a branch of computer science that focuses on creating intelligent machines that can think and act like humans. AI systems are designed to learn from their environment and experiences, and can be used to solve complex problems and automate tasks. AI is used in a variety of applications, including robotics, natural language processing, computer vision, and machine learning.\n"
     ]
    }
   ],
   "source": [
    "question = \"When elon musk born\"\n",
    "res = llm_chain.run(question)\n",
    "print(resp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31597818",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb5fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b37d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5712c15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chat model\n",
    "chat_model = ChatOpenAI()\n",
    "\n",
    "# Initialize the conversation memory\n",
    "memory = ConversationBufferMemory(memory_key=\"history\", return_messages=True)\n",
    "\n",
    "# Create a ConversationChain with the chat model and memory\n",
    "conversation = ConversationChain(llm=chat_model, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62da141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    prompt = input(\"Prompt: \")\n",
    "    \n",
    "    if prompt.upper() == 'q':\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        response = conversation.run(prompt)\n",
    "        print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb516802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continue the conversation\n",
    "response = conversation.run(\"what was his first company name\")\n",
    "\n",
    "# Access the response and chat history\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ebbcebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0825e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cfb0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6405878",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493463b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99643b61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b48f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975e2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.vectorstores import Vectara\n",
    "from langchain.vectorstores.vectara import VectaraRetriever\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders.csv_loader import CSVLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36e83bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_loader = CSVLoader(\"result.csv\")\n",
    "data = csv_loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "075beaf7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Document' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the relevant text data from the CSV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m documents \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the vector store for document retrieval\u001b[39;00m\n\u001b[0;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Extract the relevant text data from the CSV\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m documents \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Initialize the vector store for document retrieval\u001b[39;00m\n\u001b[0;32m      5\u001b[0m documents \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m data]\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Document' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# Extract the relevant text data from the CSV\n",
    "documents = [row[\"text\"] for row in data]\n",
    "\n",
    "# Initialize the vector store for document retrieval\n",
    "documents = [Document(page_content=row[\"text\"]) for row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c922167",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "llm = OpenAI(openai_api_key=openai_api_key, temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fbc192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize the document retriever\n",
    "retriever = vectorstore.as_retriever(lambda_val=0.025, k=5, filter=None)\n",
    "\n",
    "# Initialize the conversation memory\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424e2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ConversationalRetrievalChain with the chat model, retriever, and memory\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8486533f",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    \n",
    "    prompt = input(\"Prompt: \")\n",
    "    \n",
    "    if prompt.upper() == 'q':\n",
    "        break\n",
    "        \n",
    "    else:\n",
    "        response = qa({\"question\": prompt})\n",
    "        print(response[\"answer\"])\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
